task:
  hub_module_url: 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'
  model:
    num_classes: 3
  train_data:
    enable_tf_data_service: false
    get_ideal_time: false
    drop_remainder: true
    global_batch_size: 32
    is_training: true
    seq_length: 256
    shuffle_buffer_size: 100
    tfds_data_dir: '/home/dan/tfds_data'
    tfds_name: 'glue/mnli'
    tfds_split: 'train'
    text_fields: ['premise', 'hypothesis']
    vocab_file: '/home/dan/checkpoints/vocab.txt'
    lower_case: true
  validation_data:
    enable_tf_data_service: false
    get_ideal_time: false
    drop_remainder: false
    global_batch_size: 32
    is_training: false
    seq_length: 256
    tfds_data_dir: '/home/dan/tfds_data'
    tfds_name: 'glue/mnli'
    tfds_split: 'validation_matched'
    text_fields: ['premise', 'hypothesis']
    vocab_file: '/home/dan/checkpoints/vocab.txt'
    lower_case: true
trainer:
  checkpoint_interval: 10000000
  max_to_keep: 5
  optimizer_config:
    learning_rate:
      polynomial:
        cycle: false
        decay_steps: 36813
        end_learning_rate: 0.0
        initial_learning_rate: 3.0e-05
        power: 1.0
      type: polynomial
    optimizer:
      type: adamw
    warmup:
      polynomial:
        power: 1
        warmup_steps: 3681
      type: polynomial
  steps_per_loop: 1000
  summary_interval: 1000
  train_steps: 6000 # 36813
  validation_interval: 6135
  validation_steps: 307